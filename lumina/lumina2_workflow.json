{
  "id": "f63b633c-d38f-45e7-8e91-79833a292588",
  "revision": 0,
  "last_node_id": 21,
  "last_link_id": 31,
  "nodes": [
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1209,
        188
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 14
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 8
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            16
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.27",
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 14,
      "type": "Note",
      "pos": [
        860,
        -50
      ],
      "size": [
        310,
        180
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "The official way to sample this model is: shift 6 with 36 steps\n\nSampling it with lower steps works but you might have to lower the shift value to reduce the amount of artifacts.\n\nEx: 20 steps with shift 3 seems to not produce artifacts"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 15,
      "type": "Note",
      "pos": [
        71.95149993896484,
        192.96051025390625
      ],
      "size": [
        319.26513671875,
        197.89625549316406
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "The \"You are an assistant... <Prompt Start> \" text before the actual prompt is the one used in the official example.\n\nThe reason it is exposed to the user like this is because the model still works if you modify or remove it."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        420,
        411.4213562011719
      ],
      "size": [
        425.27801513671875,
        180.6060791015625
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 31
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            6
          ]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.27",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "blurry, ugly, bad, deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, cropped, out of frame, worst quality, low quality, jpeg artifacts, fused fingers, morbid, mutilated, extra fingers, mutated hands, bad anatomy, bad proportion, extra limbs",
        [
          false,
          true
        ]
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 4,
      "type": "CheckpointLoaderSimple",
      "pos": [
        72.95474243164062,
        451.1570129394531
      ],
      "size": [
        315,
        98
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            18,
            28
          ]
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 1,
          "links": [
            30,
            31
          ]
        },
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 2,
          "links": [
            8
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.27",
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "luminaImage20_baseModel.safetensors"
      ]
    },
    {
      "id": 9,
      "type": "SaveImage",
      "pos": [
        1469.457275390625,
        -62.67449951171875
      ],
      "size": [
        733.1611938476562,
        813.8931884765625
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 16
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.27",
        "Node name for S&R": "SaveImage"
      },
      "widgets_values": [
        "ComfyUI",
        ""
      ]
    },
    {
      "id": 11,
      "type": "ModelSamplingAuraFlow",
      "pos": [
        484.7452697753906,
        -158.52064514160156
      ],
      "size": [
        315,
        58
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 29
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            26
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.27",
        "Node name for S&R": "ModelSamplingAuraFlow"
      },
      "widgets_values": [
        6
      ]
    },
    {
      "id": 20,
      "type": "PatchModelAddDownscale",
      "pos": [
        461.3620300292969,
        -54.481651306152344
      ],
      "size": [
        352.79998779296875,
        202
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 26
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            27
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.27",
        "Node name for S&R": "PatchModelAddDownscale"
      },
      "widgets_values": [
        3,
        2,
        0,
        0.35,
        true,
        "bicubic",
        "bicubic"
      ]
    },
    {
      "id": 13,
      "type": "EmptySD3LatentImage",
      "pos": [
        475.8584899902344,
        640.0861206054688
      ],
      "size": [
        315,
        106
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            17
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.27",
        "Node name for S&R": "EmptySD3LatentImage"
      },
      "widgets_values": [
        1440,
        1920,
        1
      ]
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        863,
        186
      ],
      "size": [
        315,
        262
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 27
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 4
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 6
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 17
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            14
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.27",
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        426469725164624,
        "randomize",
        40,
        4,
        "gradient_estimation",
        "sgm_uniform",
        1
      ]
    },
    {
      "id": 21,
      "type": "LoraLoaderModelOnly",
      "pos": [
        76.019287109375,
        47.47138214111328
      ],
      "size": [
        315,
        82
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 28
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            29
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.27",
        "Node name for S&R": "LoraLoaderModelOnly"
      },
      "widgets_values": [
        "Hina/luminaAnimeMixLora_v0.1-rank16.safetensors",
        0.9000000000000001
      ]
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        420,
        190
      ],
      "size": [
        423.83001708984375,
        177.11770629882812
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 30
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            4
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.27",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "You are an assistant designed to generate superior illustrious style anime images with the superior degree of image-text alignment based on textual prompts or user prompts. <Prompt Start>  \n1girl, armpits, black sports bra, breasts, closed mouth, clothes around waist, cloud, cloudy sky, dark-skinned female, dark skin, fire, forest, full moon, groin, hair between eyes, jacket, jacket around waist, katana, large breasts, linea alba, long hair, looking at viewer, moon, nature, navel, night, night sky, official alternate eye color, official alternate hairstyle, ootachi, pants, plant, purple ribbon, pyrokinesis, red eyes, red hair, red jacket, red pants, red track suit, ribbon, sky, solo, sports bra, star \\(sky\\), starry sky, tan, toned, tree, very long hair,\n\n",
        [
          false,
          true
        ]
      ],
      "color": "#232",
      "bgcolor": "#353"
    }
  ],
  "links": [
    [
      4,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      6,
      7,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      8,
      4,
      2,
      8,
      1,
      "VAE"
    ],
    [
      14,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      16,
      8,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      17,
      13,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      26,
      11,
      0,
      20,
      0,
      "MODEL"
    ],
    [
      27,
      20,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      28,
      4,
      0,
      21,
      0,
      "MODEL"
    ],
    [
      29,
      21,
      0,
      11,
      0,
      "MODEL"
    ],
    [
      30,
      4,
      1,
      6,
      0,
      "CLIP"
    ],
    [
      31,
      4,
      1,
      7,
      0,
      "CLIP"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.7972024500000038,
      "offset": [
        455.9898136445039,
        311.4582002821469
      ]
    },
    "ue_links": [],
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}